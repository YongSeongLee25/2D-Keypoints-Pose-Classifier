{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081f3f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "import math\n",
    "from glob import glob\n",
    "import warnings\n",
    "# import pickle\n",
    "# import joblib\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def concat_df(file_path, class_num):\n",
    "    files = sorted(glob(file_path))\n",
    "    assert len(files) != 0, 'csv file is none'\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for file in files:\n",
    "        csv_df = pd.read_csv(file)\n",
    "        df = pd.concat([df, csv_df.loc[:,'nose':'right_ankle_y']])\n",
    "        df['class'] = class_num\n",
    "    \n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "file_path_stop = 'path/to/stop'\n",
    "file_path_change = 'path/to/change'\n",
    "\n",
    "stop_data = concat_df(file_path_stop, 0) # class 0\n",
    "chg_data = concat_df(file_path_change, 1) # class 1\n",
    "\n",
    "concat_data = pd.concat([stop_data, chg_data])\n",
    "data = concat_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "label = data['class']\n",
    "data = data.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d588d2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predict:\n",
    "    def __init__(self, clf, x_train, y_train, x_val, y_val, cv, params):\n",
    "        self.trainX = x_train\n",
    "        self.trainY = y_train\n",
    "        self.valX = x_val\n",
    "        self.valY = y_val\n",
    "        self.clf = clf\n",
    "        self.cv = cv\n",
    "        self.params = params\n",
    "        \n",
    "    # inference class\n",
    "    def predictTest(self):\n",
    "        self.clf.fit(self.trainX, self.trainY)\n",
    "        self.result = vote.predict(self.valX)\n",
    "        return self.result\n",
    "\n",
    "    # accuracy score\n",
    "    def accScore(self):\n",
    "        return accuracy_score(self.valY, self.result)\n",
    "\n",
    "    # cross vaildation\n",
    "    def crossVail(self):\n",
    "        score = cross_val_score(self.clf, self.trainX, self.trainY, cv = self.cv)\n",
    "        df = pd.DataFrame(cross_validate(self.clf, self.trainX, self.trainY, cv = self.cv))\n",
    "        return score, df\n",
    "\n",
    "    # GridSearch CV\n",
    "    def gridBestparam(self):\n",
    "        grid = GridSearchCV(estimator=self.clf, param_grid=self.params, cv=self.cv)\n",
    "        grid.fit(self.trainX, self.trainY)\n",
    "        return grid.best_params_\n",
    "\n",
    "# normalization -1 ~ 1\n",
    "class Normalization:\n",
    "    def __init__(self, df, head, torso, leg):\n",
    "        self.df = df\n",
    "        self.body_list = [head, torso, leg]\n",
    "        self.joint_len = 17\n",
    "        \n",
    "    def listSum(self):\n",
    "        return [sum(data) for data in zip(*self.body_list)]\n",
    "        \n",
    "    def jointCenter(self, xy):\n",
    "        return xy.iloc[:,:].sum(axis=1) / self.joint_len\n",
    "\n",
    "    def jointNorm(self, xy, body, centr):\n",
    "        col_list = xy.columns\n",
    "        for col in col_list:\n",
    "            xy.loc[:,col] = (xy.loc[:,col] - centr) / body\n",
    "        return xy\n",
    "    \n",
    "    def startNormal(self):\n",
    "        body = self.listSum()\n",
    "        X = self.df.iloc[:, :self.joint_len]\n",
    "        Y = self.df.iloc[:, self.joint_len:]\n",
    "        \n",
    "        centrX = self.jointCenter(X)\n",
    "        centrY = self.jointCenter(Y)\n",
    "        normX = self.jointNorm(X, body, centrX)\n",
    "        normY = self.jointNorm(Y, body, centrY)\n",
    "        dataframe = pd.merge(normX.copy(), normY.copy(), left_index=True, right_index=True, how='left')\n",
    "        return dataframe\n",
    "    \n",
    "class Maxjoint:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.df_len = len(df)\n",
    "        self.dis_list = []\n",
    "        self.length = 0\n",
    "    \n",
    "    def maxiMum(self):\n",
    "        return np.maximum.reduce(self.dis_list).tolist()\n",
    "        \n",
    "    def jointSum(self):\n",
    "        return [sum(data) for data in zip(*self.dis_list)]\n",
    "    \n",
    "    def disTance(self, x1,x2,y1,y2):\n",
    "        self.x1 = self.df[x1]\n",
    "        self.x2 = self.df[x2]\n",
    "        self.y1 = self.df[y1]\n",
    "        self.y2 = self.df[y2]\n",
    "        self.result = []\n",
    "        \n",
    "        for idx in range(self.df_len):\n",
    "            self.length = math.sqrt((self.x2[idx]-self.x1[idx])**2 + (self.y2[idx]-self.y1[idx])**2)\n",
    "            self.result.append(self.length)\n",
    "        self.dis_list.append(self.result)\n",
    "        return self.dis_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ec8599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "\n",
    "headmax = Maxjoint(data)\n",
    "torsomax = Maxjoint(data)\n",
    "legleft = Maxjoint(data)\n",
    "legright = Maxjoint(data)\n",
    "\n",
    "headmax.disTance('nose', 'left_eye', 'nose_y', 'left_eye_y')\n",
    "headmax.disTance('nose', 'right_eye', 'nose_y', 'right_eye_y')\n",
    "headmax.disTance('nose','left_ear','nose_y','left_ear_y')\n",
    "headmax.disTance('nose','right_ear','nose_y','right_ear_y')\n",
    "head = headmax.maxiMum()\n",
    "\n",
    "torsomax.disTance('left_shoulder', 'left_hip', 'left_shoulder_y', 'left_hip_y')\n",
    "torsomax.disTance('right_shoulder', 'right_hip', 'right_shoulder_y', 'right_hip_y')\n",
    "torso = torsomax.maxiMum()\n",
    "\n",
    "legleft.disTance('left_hip', 'left_knee', 'left_hip', 'left_knee')\n",
    "legleft.disTance('left_knee', 'left_ankle', 'left_knee_y', 'left_ankle_y')\n",
    "leg_left = legleft.jointSum()\n",
    "\n",
    "legright.disTance('right_hip', 'right_knee', 'right_hip', 'right_knee')\n",
    "legright.disTance('right_knee', 'right_ankle', 'right_knee_y', 'right_ankle_y')\n",
    "leg_right = legright.jointSum()\n",
    "\n",
    "leg = np.maximum.reduce([leg_left, leg_right]).tolist()\n",
    "normal = Normalization(data, head, torso, leg)\n",
    "dataframe = normal.startNormal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4844450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line(a, b):\n",
    "    if (a.any()> 0 and b.any()>0): plt.plot([a[0], b[0]], [a[1], b[1]], 'k-')\n",
    "        \n",
    "def plot_skeleton(sample, pattern):\n",
    "    \n",
    "    keypoint = ['Nose', 'LEye', 'REye', 'LEar', 'REar', 'LShoulder', 'RShoulder',\n",
    "                'LElbow', 'RElbow', 'LWrist', 'RWrist', 'LHip', 'RHip', 'LKnee', 'RKnee', 'LAnkle', 'RAnkle']\n",
    "    \n",
    "    for i in range(len(sample)//2):\n",
    "        plt.plot(sample[i], sample[17+i], pattern)\n",
    "        plt.text(sample[i], sample[17+i], keypoint[i], verticalalignment='bottom' , horizontalalignment='center' )\n",
    "    skeleton = sample\n",
    "    Nose = skeleton[[0,17]]\n",
    "    LEye = skeleton[[1,18]]\n",
    "    REye = skeleton[[2,19]]\n",
    "    LEar = skeleton[[3,20]]\n",
    "    REar = skeleton[[4,21]]\n",
    "    LShoulder = skeleton[[5,22]]\n",
    "    RShoulder = skeleton[[6,23]]\n",
    "    LElbow = skeleton[[7,24]]\n",
    "    RElbow = skeleton[[8,25]]\n",
    "    LWrist = skeleton[[9,26]]\n",
    "    RWrist = skeleton[[10,27]]\n",
    "    LHip = skeleton[[11,28]]\n",
    "    RHip = skeleton[[12,29]]\n",
    "    LKnee = skeleton[[13,30]]\n",
    "    RKnee = skeleton[[14,31]]\n",
    "    LAnkle = skeleton[[15,32]]\n",
    "    RAnkle = skeleton[[16,33]]\n",
    "    \n",
    "    plot_line(LEye, Nose)\n",
    "    plot_line(REar, REye)\n",
    "    plot_line(REye, Nose)\n",
    "    plot_line(LEar, LEye)\n",
    "    plot_line(LShoulder, LElbow)\n",
    "    plot_line(LElbow, LWrist)\n",
    "    plot_line(RShoulder, RElbow)\n",
    "    plot_line(RElbow, RWrist)\n",
    "    plot_line(LHip, LKnee)\n",
    "    plot_line(LKnee, LAnkle)\n",
    "    plot_line(RKnee, RAnkle)\n",
    "    plot_line(RHip, RKnee)\n",
    "    plot_line(LHip, LShoulder)\n",
    "    plot_line(RHip, RShoulder)\n",
    "    plot_line(RHip, LHip)\n",
    "    plot_line(LShoulder, RShoulder)\n",
    "    plot_line(LShoulder, Nose)\n",
    "    plot_line(RShoulder, Nose)\n",
    "    \n",
    "def plot(sample, centr):\n",
    "    \n",
    "    if centr==0:\n",
    "        pad_ori = 38\n",
    "        plt.figure(str(sample))\n",
    "        plt.subplot(131)\n",
    "        plt.title('Original skeleton')\n",
    "        X_ori = sample\n",
    "        x_max = max(X_ori[:17]) + pad_ori\n",
    "        x_min = min(i for i in X_ori[:17] if i > 0) - pad_ori\n",
    "        y_max = max(X_ori[17:]) + pad_ori\n",
    "        y_min = min(j for j in X_ori[17:] if j > 0) - pad_ori\n",
    "        plt.xlim(x_min,x_max)\n",
    "        plt.ylim(y_max, y_min)\n",
    "        plot_skeleton(X_ori, 'bo')\n",
    "    \n",
    "    if centr==1:\n",
    "        X_nor = sample\n",
    "        pad_nor = 0.2\n",
    "        #plt.figure(2)\n",
    "        plt.subplot(131)\n",
    "        plt.title('Normalized skeleton')\n",
    "        x_max = max(X_nor[:17]) + pad_nor\n",
    "        x_min = min(X_nor[:17]) - pad_nor\n",
    "        y_max = max(X_nor[17:]) + pad_nor\n",
    "        y_min = min(X_nor[17:]) - pad_nor\n",
    "        plt.xlim(x_min,x_max)\n",
    "        plt.ylim(y_max, y_min)\n",
    "        plot_skeleton(X_nor, 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca878b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "plot(dataframe.iloc[0, :], 1)\n",
    "# original\n",
    "plot(data.iloc[0, :], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11da6dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML inference\n",
    "x_train, x_val, y_train, y_val = train_test_split(dataframe, label, test_size=0.3, random_state=42)\n",
    "\n",
    "clf1 = RandomForestClassifier(n_estimators = 30, max_depth=3, random_state=42)\n",
    "clf2 = LogisticRegression(C = 0.5, random_state=42)\n",
    "clf3 = SVC(kernel = 'linear', C = 1.2, probability=True, random_state=42)\n",
    "clf4 = LGBMClassifier(learning_rate = 0.1, max_depth = 3)\n",
    "\n",
    "vote = VotingClassifier(estimators=[\n",
    "    ('rf', clf1),('lr', clf2),('svc',clf3),('lgbm',clf4)\n",
    "], voting='soft')\n",
    "\n",
    "\n",
    "votings = Predict(vote, x_train, y_train, x_val, y_val, 5, 'None')\n",
    "\n",
    "print(votings.predictTest())\n",
    "print(votings.accScore())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
